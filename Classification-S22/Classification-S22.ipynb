{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <h1><center>Machine Learning</center></h1>\n",
    "\n",
    "<center><img src="img/title.jpg" align="center"/></center>\n",
    "\n",
    "\n",
    "<h3 style=\"color:blue;\"><center>Instructor: Fereydoon Vafaei</center></h3>\n",
    "\n",
    "\n",
    "<h5 style=\"color:purple;\"><center>Classification</center></h5>\n",
    "\n",
    "<center><img src=\"img/UMBC_logo.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Agenda</center></h1>\n",
    "\n",
    "- Classification: Concept, Definition, and Mathematical Notation\n",
    "\n",
    "- Classification Example: MNIST Dataset\n",
    "\n",
    "- Binary Classification\n",
    "\n",
    "- Errors and Confusion Matrix\n",
    "\n",
    "- Performance Measures\n",
    "\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "    - ROC Curve and Area Under Curve (AUC)\n",
    "\n",
    "- Multi-class Classification\n",
    "    - OvR and OvO strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Supervised Learning - Classification</center></h1>\n",
    "\n",
    "<center><img src=\"img/supervised.jpg\" align=\"center\"/></center>\n",
    "\n",
    "<font size=1>Image from Hands-On ML Textbook</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Classification Model - Classifier</center></h1>\n",
    "\n",
    "<center><img src=\"img/spam.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size=1>Image from: https://developers.google.com/machine-learning/guides/text-classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Review - ML Pipeline</center></h1>\n",
    "\n",
    "<center><img src=\"img/pipeline.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size=1>Image from: https://developers.google.com/machine-learning/guides/text-classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Classification: Concept and Definition</center></h1>\n",
    "\n",
    "- Classification is a **Supervised Learning** task.\n",
    "\n",
    "\n",
    "- In this type of task, the computer program is asked to specify which of $k$ categories an input belongs to.\n",
    "\n",
    "\n",
    "- To solve this task, the learning algorithm is usually asked to produce a function $f$\n",
    "    - $f: \\mathcal{X} \\rightarrow y $\n",
    "    - Input: $\\mathbf{x} \\in {\\rm I\\!R}^d = \\mathcal{X}$\n",
    "\n",
    "\n",
    "- The model assigns an input described by vector $X$ to a category identiﬁed by numeric code $y$.\n",
    "\n",
    "\n",
    "- There are other variants of the classiﬁcation task, for example, where $f$  outputs a probability distribution over classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Image Classification and Object Recognition</center></h1>\n",
    "\n",
    "- An example of a classiﬁcation task is **object recognition**, where the input is an image (usually described as a set of pixel brightness values), and the output is a numeric code identifying the object in the image.\n",
    "\n",
    "\n",
    "- **Object recognition** is the same basic technology that enables computers to recognize faces, which can be used to automatically tag people in photo collections and for computers to interact more naturally with their users.\n",
    "\n",
    "<center><img src=\"img/object-recognition.jpg\" align=\"center\"/></center>\n",
    "\n",
    "<font size=1>Image from: https://www.facebook.com/pg/ObjectReco/posts/</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Classification - Mathematical Notation</center></h1>\n",
    "\n",
    "- $f: \\mathcal{X} \\rightarrow y $\n",
    "- Input: $\\mathbf{x} \\in {\\rm I\\!R}^d = \\mathcal{X}$\n",
    "- Output: $y \\in \\{-1, +1\\}$\n",
    "- Data: $D = \\{ (\\mathbf{x}_1, y_1), \\dots, (\\mathbf{x}_N, y_N) \\}$ where $y_i = f(\\mathcal{x}_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Classification Example: MNIST Dataset</center></h1>\n",
    "\n",
    "- MNIST is known to be \"Hello World!\" dataset in ML.\n",
    "\n",
    "\n",
    "- 70000 images of handwritten digits (0-9) with the size of 28x28 grayscale.\n",
    "\n",
    "\n",
    "- The task is classifying each image to identify the number (0-9) from image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# From: https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    1,    21,    34,    37,    51,    56,    63,    68,    69,\\n               75,\\n            ...\\n            59910, 59917, 59927, 59939, 59942, 59948, 59969, 59973, 59990,\\n            59992],\\n           dtype='int64', length=60000)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     mnist \u001b[38;5;241m=\u001b[39m fetch_openml(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_784\u001b[39m\u001b[38;5;124m'\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     mnist\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint8) \u001b[38;5;66;03m# fetch_openml() returns targets as strings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[43msort_by_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# fetch_openml() returns an unsorted dataset\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_mldata\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36msort_by_target\u001b[1;34m(mnist)\u001b[0m\n\u001b[0;32m      2\u001b[0m reorder_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28msorted\u001b[39m([(target, i) \u001b[38;5;28;01mfor\u001b[39;00m i, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mnist\u001b[38;5;241m.\u001b[39mtarget[:\u001b[38;5;241m60000\u001b[39m])]))[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m reorder_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28msorted\u001b[39m([(target, i) \u001b[38;5;28;01mfor\u001b[39;00m i, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mnist\u001b[38;5;241m.\u001b[39mtarget[\u001b[38;5;241m60000\u001b[39m:])]))[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m mnist\u001b[38;5;241m.\u001b[39mdata[:\u001b[38;5;241m60000\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreorder_train\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m mnist\u001b[38;5;241m.\u001b[39mtarget[:\u001b[38;5;241m60000\u001b[39m] \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mtarget[reorder_train]\n\u001b[0;32m      6\u001b[0m mnist\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m60000\u001b[39m:] \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mdata[reorder_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m60000\u001b[39m]\n",
      "File \u001b[1;32m~\\.virtualenvs\\Slides_-_Private_Github-kiS0N02v\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\Slides_-_Private_Github-kiS0N02v\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\Slides_-_Private_Github-kiS0N02v\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([    1,    21,    34,    37,    51,    56,    63,    68,    69,\\n               75,\\n            ...\\n            59910, 59917, 59927, 59939, 59942, 59948, 59969, 59973, 59990,\\n            59992],\\n           dtype='int64', length=60000)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n",
    "    sort_by_target(mnist) # fetch_openml() returns an unsorted dataset\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Each image has 784 features. Features are pixel intensities.\n",
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "example_images = np.r_[X[:12000:600], X[13000:30600:600], X[30600:60000:590]]\n",
    "plot_digits(example_images, images_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This is one way of splitting data to training set and testing set. \n",
    "# You may also use sklearn.model_selection.train_test_split\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's classify if the number is 5 or not\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "print(y_train_5.shape)\n",
    "print(y_test_5.shape)\n",
    "print(len(y_train_5[y_train_5==True])) # 10% of training examples are positive\n",
    "print(len(y_train_5[y_train_5==False]))\n",
    "print(len(y_test_5[y_test_5==True])) # 10% of test examples are positive\n",
    "print(len(y_test_5[y_test_5==False])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Stochastic Gradient Descent Classifier from sklearn on MNIST dataset.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\n",
    "\n",
    "# Training set is used to train the model. This will be a binary classifier to recognize '5' versus the rest.\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Once trained, the model can be used to make predictions on new instances or test set.\n",
    "y_pred = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# There are different metrics to use for model evaluation. One metric is accuracy.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test_5, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Binary Classification</center></h1>\n",
    "\n",
    "- Binary classification is classifying two classes/labels such as positive vs negative, yes/no, {0, 1}, healthy vs patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Errors in Binary Classification</center></h1>\n",
    "<h3><center>Example: Classification of Autism Spectrum Disorder (ASD)</center></h3>\n",
    "\n",
    "<b>True Positive (TP)</b>: Subject is ASD-Pos and model predicted ASD-Pos. Model is correct! :)\n",
    "\n",
    "<b>True Negative (TN)</b>: Subject is ASD-Neg and model predicted ASD-Neg. Model is correct! :)\n",
    "\n",
    "<b>False Positive (FP)</b>: Subject is ASD-Neg but model predicted ASD-Pos. Model is wrong! :(\n",
    "\n",
    "<b>False Negative (FN)</b>: Subject is ASD-Pos but model predicted ASD-Neg. Model is wrong! :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Confusion Matrix</center></h1>\n",
    "\n",
    "<center><img src=\"img/confusion_matrix.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# The actual labels in the test set\n",
    "y_test = [\"ASD-Pos\", \"ASD-Neg\", \"ASD-Pos\", \"ASD-Neg\"]\n",
    "\n",
    "# The labels predicted by the model\n",
    "y_pred = [\"ASD-Pos\", \"ASD-Neg\", \"ASD-Pos\", \"ASD-Neg\"]\n",
    "confusion_matrix(y_test, y_pred).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Performance Measures</center></h1>\n",
    "\n",
    "- Accuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Precision = $\\frac{TP}{TP + FP}$ The lower number of False Positives (FP), the higher Precision.\n",
    "\n",
    "- Recall = $\\frac{TP}{TP + FN}$  The lower number of False Negatives (FN), the higher recall.\n",
    "\n",
    "- f1_score = $2 \\times \\frac{Precision \\times Recall}{Precision + Recall} = \\frac{TP}{TP + \\frac{FP + FN}{2}}$\n",
    "\n",
    "There are also other [performance metrics](https://en.wikipedia.org/wiki/Precision_and_recall#Imbalanced_Data) used in model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> <font color=\"blue\">Active Learning</font>: Confusion Matrix and Performance Measures</center></h1>\n",
    "\n",
    ">Calculate [confusion matrix, accuracy, precision, recall, and f1_score for this problem](ActiveLearning-Binary-Classification.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_test = [\"ASD-Pos\", \"ASD-Pos\", \"ASD-Pos\", \"ASD-Neg\", \"ASD-Neg\", \"ASD-Neg\", \"ASD-Neg\", \"ASD-Neg\", \"ASD-Pos\", \"ASD-Neg\"]\n",
    "y_pred = [\"ASD-Pos\", \"ASD-Pos\", \"ASD-Pos\", \"ASD-Neg\", \"ASD-Pos\", \"ASD-Pos\", \"ASD-Pos\", \"ASD-Neg\", \"ASD-Pos\", \"ASD-Neg\"]\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, labels=['ASD-Pos', 'ASD-Neg']).T)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred, pos_label='ASD-Pos'))\n",
    "print('recall = ', recall_score(y_test, y_pred, pos_label='ASD-Pos'))\n",
    "print('f1 score = ', f1_score(y_test, y_pred, pos_label='ASD-Pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Precision/Recall Tradeoff</center></h1>\n",
    "\n",
    "- Generally, attempts of increasing precision would reduce recall, and vice versa. This is called the precision/recall trade-off.\n",
    "\n",
    "\n",
    "- In some problems precision is favored (e.g. spam-filtering) while in other problems recall may be favored (e.g. disease diagnosis).\n",
    "\n",
    "<center><img src=\"img/precision-recall.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Hands-On ML Textbook</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Precision/Recall Tradeoff</center></h1>\n",
    "\n",
    "- As you see in this plot for MNIST dataset, lowering the classification threshold increases recall and reduces precision.\n",
    "\n",
    "\n",
    "- In some problems precision is favored (e.g. spam-filtering) while in other problems recall may be favored (e.g. disease diagnosis).\n",
    "\n",
    "<center><img src=\"img/threshold.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Hands-On ML Textbook</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>ROC Curve and Area Under Curve (AUC)</center></h1>\n",
    "\n",
    "- The ROC curve plots the True Positive Rate (TPR - another name for recall aka sensitivity) against the False Positive Rate (FPR).\n",
    "\n",
    "<center><img src=\"img/roc.png\" align=\"center\"/></center>\n",
    "\n",
    "<font size='1'>Image from Hands-On ML Textbook</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>ROC Curve and Area Under Curve (AUC)</center></h1>\n",
    "\n",
    "- The ROC curve plots the True Positive Rate (TPR) on y-axis against the False Positive Rate (FPR) on x-axis.\n",
    "\n",
    "\n",
    "- TPR is another name for recall (aka sensitivity) $TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "\n",
    "- The FPR is the ratio of negative instances that are incorrectly classified as positive. $FPR = \\frac{FP}{FP + TN} = 1 - TNR$\n",
    "\n",
    "\n",
    "\n",
    "- True Negative Rate (TNR) is the ratio of negative instances that are correctly classified as negative. The TNR is also called specificity. Hence, the ROC curve plots sensitivity (recall) versus $1 - specificity$.\n",
    "\n",
    "\n",
    "- $TNR = \\frac{TN}{TN + FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Multi-Class Classification</center></h1>\n",
    "\n",
    "- Some classifiers such as SGD classifiers, Random Forest classifiers, and Neural Networks are capable of handling multiple classes natively.\n",
    "\n",
    "\n",
    "- Other classifiers (such as Logistic Regression or Support Vector Machine classifiers) are strictly **binary classifiers**, but different strategies can be used to reframe the problem to a binary classification problem. In this case, multiple classifiers are needed:\n",
    "\n",
    "    - **OvR** (OvA): One versus Rest\n",
    "    - **OvO**: One versus One \n",
    "   \n",
    "   \n",
    "- **Question-1**: How many classifiers are needed for OvR and OvO strategies for an N-class problem?\n",
    "\n",
    "- **Question-2**: How many classifiers are needed for OvR and OvO strategies for MNIST dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- OvR (OvA): One versus Rest, N Classifiers needed for an N-class problem\n",
    "    \n",
    "    \n",
    "- OvO: One versus One  $\\frac{N(N-1)}{2}$ Classifiers needed for an N-class problem"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
